{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a training data set for classification of political offiliation\n",
    "\n",
    "This notebook collects transcripts from presidential candidate debates and labels them with the appropriate 'democrat' or 'republican' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup                                                                                   # needed for parsing HTML\n",
    "\n",
    "import contractions                                                                                             # contractions dictionary\n",
    "from string import punctuation\n",
    "\n",
    "import spacy                                                                                                    # used for lemmatization/stemming\n",
    "#!python -m spacy download en_core_web_sm                # OR in Jupyter download in terminal using spacy download en_core_web_sm\n",
    "\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = ToktokTokenizer()                                                                                   # stopword removal\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Initialize NLTK's WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts from democratic debates for 2020 election\n",
    "\n",
    "dem_urls = [\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-washington-dc',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-charleston-south-carolina-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-las-vegas-nevada-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-manchester-new-hampshire-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-des-moines-iowa-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-los-angeles-california',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-atlanta-georgia',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-westerville-ohio',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-houston-texas',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-detroit-michigan-group-2',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-detroit-michigan-group-1',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-miami-florida-group-2',\n",
    "    'https://www.presidency.ucsb.edu/documents/democratic-candidates-debate-miami-florida-group-1'\n",
    "]\n",
    "\n",
    "# transcripts from republican debates for 2016 election\n",
    "\n",
    "rep_urls = [\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-miami-florida',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-detroit-michigan',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-houston-texas',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-greenville-south-carolina',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-manchester-new-hampshire-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-des-moines-iowa-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-north-charleston-south-carolina',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-las-vegas-nevada-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-milwaukee-wisconsin',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-boulder-colorado',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-simi-valley-california-0',\n",
    "    'https://www.presidency.ucsb.edu/documents/republican-candidates-debate-cleveland-ohio'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for scraping from the urls and removing html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_format_text(url):\n",
    "    try:\n",
    "        # Send a request to the URL\n",
    "        response = request.urlopen(url)\n",
    "        # Read and decode the response\n",
    "        raw = response.read().decode('utf-8-sig')\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(raw, 'html.parser')\n",
    "        # Extract the text from the parsed HTML (you can customize this based on the website structure)\n",
    "        text = soup.get_text()\n",
    "        # Clean the text (add more cleaning steps if needed)\n",
    "        cleaned_text = text.strip()\n",
    "        return cleaned_text\n",
    "    except Exception as e:\n",
    "        # Handle exceptions if the URL request fails\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for getting rid of non-debate text and organizing into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcript(transcript):\n",
    "    # Define a regular expression pattern to identify speaker lines\n",
    "    pattern = r'^([^:]+):(.*)$'\n",
    "\n",
    "    lines = [line.strip() for line in transcript.split('\\n') if line.strip()]\n",
    "    data = []\n",
    "    current_speaker = None\n",
    "    current_speech = []\n",
    "\n",
    "    for line in lines:\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            # If a line starts with a name, store the current speaker and speech\n",
    "            if current_speaker:\n",
    "                data.append({\"Speaker\": current_speaker, \"Speech\": \" \".join(current_speech)})\n",
    "            current_speaker, speech_part = match.groups()\n",
    "            current_speech = [speech_part.strip()]\n",
    "        elif current_speaker:\n",
    "            # If it doesn't start with a name, consider it as part of the current speech\n",
    "            current_speech.append(line.strip())\n",
    "\n",
    "    # Append the last speaker and their speech\n",
    "    if current_speaker:\n",
    "        data.append({\"Speaker\": current_speaker, \"Speech\": \" \".join(current_speech)})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "labels = []\n",
    "\n",
    "for url in dem_urls:\n",
    "    transcript = scrape_and_format_text(url)\n",
    "    df = process_transcript(transcript)\n",
    "\n",
    "    # Check if the DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        documents.append(df)\n",
    "\n",
    "# Concatenate the list of DataFrames into a single DataFrame\n",
    "dem_df = pd.concat(documents, ignore_index=True)\n",
    "dem_df['label'] = 'democrat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "labels = []\n",
    "\n",
    "for url in rep_urls:\n",
    "    transcript = scrape_and_format_text(url)\n",
    "    df = process_transcript(transcript)\n",
    "\n",
    "    # Check if the DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        documents.append(df)\n",
    "\n",
    "# Concatenate the list of DataFrames into a single DataFrame\n",
    "rep_df = pd.concat(documents, ignore_index=True)\n",
    "rep_df['label'] = 'republican'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dem and rep dataframes\n",
    "df = pd.concat([dem_df, rep_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unwanted sections from debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with participants that equal 'MODERATORS' or \"PARTICIPANTS\" or \"NOTE\"\n",
    "# also drop rows with www. in the speech\n",
    "df = df[df.Speaker != 'MODERATORS']\n",
    "df = df[df.Speaker != 'PARTICIPANTS']\n",
    "df = df[df.Speaker != 'NOTE']\n",
    "df = df[~df.Speech.str.contains(\"www.\")]\n",
    "df = df[df['Speaker'].str.isupper()]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "democrat      5651\n",
       "republican    4756\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value counts for each label\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\\r\\n|\\r\\n]+', '\\n', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub('’', '', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the clean_text function to the 'Speech' column of the DataFrame\n",
    "df['clean_speech'] = df['Speech'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with empty clean_speech\n",
    "df = df[df.clean_speech != '']\n",
    "# drop rows with nan clean_speech\n",
    "df = df.dropna(subset=['clean_speech'])\n",
    "# drop rows with less None\n",
    "df = df[df.clean_speech != 'none']\n",
    "# drop rows with less than 10 characters\n",
    "df = df[df.clean_speech.str.len() > 10]\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speech</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAPPER</td>\n",
       "      <td>Good evening from Washington, D.C. And welcome...</td>\n",
       "      <td>democrat</td>\n",
       "      <td>good evening washington dc welcome unique even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BASH</td>\n",
       "      <td>We come together tonight at an extraordinary t...</td>\n",
       "      <td>democrat</td>\n",
       "      <td>come together tonight extraordinary time count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALDERON</td>\n",
       "      <td>The setting of this debate is also different. ...</td>\n",
       "      <td>democrat</td>\n",
       "      <td>setting debate also different reduce unnecessa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TAPPER</td>\n",
       "      <td>And all of this comes, of course, as four more...</td>\n",
       "      <td>democrat</td>\n",
       "      <td>come course four state florida arizona ohio il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIDEN</td>\n",
       "      <td>Well, first of all, my heart goes out to those...</td>\n",
       "      <td>democrat</td>\n",
       "      <td>well first heart go already lost someone suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>BUSH</td>\n",
       "      <td>Here's what I believe. I believe we're at the ...</td>\n",
       "      <td>republican</td>\n",
       "      <td>here believe believe verge greatest time alive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>BAIER</td>\n",
       "      <td>Mr. Trump, closing statement, sir.</td>\n",
       "      <td>republican</td>\n",
       "      <td>mr trump closing statement sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>Our country is in serious trouble. We don't wi...</td>\n",
       "      <td>republican</td>\n",
       "      <td>country serious trouble dont win anymore dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>BAIER</td>\n",
       "      <td>Gentlemen, thank you.</td>\n",
       "      <td>republican</td>\n",
       "      <td>gentleman thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>KELLY</td>\n",
       "      <td>Are you relieved? You were nervous before, the...</td>\n",
       "      <td>republican</td>\n",
       "      <td>relieved nervous dont look relieved look get o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9122 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Speaker                                             Speech       label  \\\n",
       "0       TAPPER  Good evening from Washington, D.C. And welcome...    democrat   \n",
       "1         BASH  We come together tonight at an extraordinary t...    democrat   \n",
       "2     CALDERON  The setting of this debate is also different. ...    democrat   \n",
       "3       TAPPER  And all of this comes, of course, as four more...    democrat   \n",
       "4        BIDEN  Well, first of all, my heart goes out to those...    democrat   \n",
       "...        ...                                                ...         ...   \n",
       "9117      BUSH  Here's what I believe. I believe we're at the ...  republican   \n",
       "9118     BAIER                 Mr. Trump, closing statement, sir.  republican   \n",
       "9119     TRUMP  Our country is in serious trouble. We don't wi...  republican   \n",
       "9120     BAIER                              Gentlemen, thank you.  republican   \n",
       "9121     KELLY  Are you relieved? You were nervous before, the...  republican   \n",
       "\n",
       "                                           clean_speech  \n",
       "0     good evening washington dc welcome unique even...  \n",
       "1     come together tonight extraordinary time count...  \n",
       "2     setting debate also different reduce unnecessa...  \n",
       "3     come course four state florida arizona ohio il...  \n",
       "4     well first heart go already lost someone suffe...  \n",
       "...                                                 ...  \n",
       "9117  here believe believe verge greatest time alive...  \n",
       "9118                     mr trump closing statement sir  \n",
       "9119  country serious trouble dont win anymore dont ...  \n",
       "9120                                    gentleman thank  \n",
       "9121  relieved nervous dont look relieved look get o...  \n",
       "\n",
       "[9122 rows x 4 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a final dataframe with only the clean_speech and label columns\n",
    "df_final = df[['clean_speech', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export as csv file\n",
    "df_final.to_csv('debates.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
