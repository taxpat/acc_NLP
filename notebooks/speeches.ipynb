{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import re  # For regular expressions\n",
    "import string  # For string operations and punctuation removal\n",
    "from nltk.tokenize import word_tokenize  # For word tokenization\n",
    "from nltk.corpus import stopwords  # For stop words\n",
    "from nltk.stem import WordNetLemmatizer  # For word lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [\"..\\data\\Trump.pdf\", \n",
    "             \"..\\data\\Obama.pdf\", \n",
    "             \"..\\data\\Bush.pdf\",\n",
    "             \"..\\data\\Biden.pdf\"]  # Replace with your list of PDF files\n",
    "\n",
    "pdf_texts = []  # List to store the text from each PDF\n",
    "\n",
    "for pdf_file_path in pdf_files:\n",
    "    pdf_file = open(pdf_file_path, \"rb\")\n",
    "\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    pdf_text = \"\"  # String to store the text from the current PDF\n",
    "\n",
    "    for page_num in range(num_pages):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "        pdf_text += page_text  # Append the page text to the PDF text\n",
    "\n",
    "    pdf_texts.append(pdf_text)  # Append the PDF text to the list\n",
    "\n",
    "    pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pdf_texts, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\\r\\n|\\r\\n]+', '\\n', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub('â€™', '', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_speech'] = df['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump  \\n01/20/2017  \\nInaugural Address  \\nCh...</td>\n",
       "      <td>trump inaugural address chief justice robert p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obam a \\n01/20/2009  \\nInaugural Address  \\n \\...</td>\n",
       "      <td>obam inaugural address stand today humbled tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bush  \\n01/20/2001  \\nInaugural Address  \\n \\n...</td>\n",
       "      <td>bush inaugural address president clinton disti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden  \\n01/20/2021  \\nInaugural Address  \\nCh...</td>\n",
       "      <td>biden inaugural address chief justice robert v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Trump  \\n01/20/2017  \\nInaugural Address  \\nCh...   \n",
       "1  Obam a \\n01/20/2009  \\nInaugural Address  \\n \\...   \n",
       "2  Bush  \\n01/20/2001  \\nInaugural Address  \\n \\n...   \n",
       "3  Biden  \\n01/20/2021  \\nInaugural Address  \\nCh...   \n",
       "\n",
       "                                        clean_speech  \n",
       "0  trump inaugural address chief justice robert p...  \n",
       "1  obam inaugural address stand today humbled tas...  \n",
       "2  bush inaugural address president clinton disti...  \n",
       "3  biden inaugural address chief justice robert v...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv ('..\\data\\cleaned_speeches.csv', index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
